{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [第1章: 準備運動](https://nlp100.github.io/ja/ch01.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [00. 文字列の逆順](https://nlp100.github.io/ja/ch01.html#00-%E6%96%87%E5%AD%97%E5%88%97%E3%81%AE%E9%80%86%E9%A0%86)\n",
    "文字列\"stressed\"の文字を逆に（末尾から先頭に向かって）並べた文字列を得よ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_00 = \"stressed\"\n",
    "out_00 = \"\".join([in_00[i] for i in range(len(in_00)-1, -1, -1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'desserts'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_00"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [01. 「パタトクカシーー」](https://nlp100.github.io/ja/ch01.html#01-%E3%83%91%E3%82%BF%E3%83%88%E3%82%AF%E3%82%AB%E3%82%B7%E3%83%BC%E3%83%BC)\n",
    "「パタトクカシーー」という文字列の1,3,5,7文字目を取り出して連結した文字列を得よ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_01 = \"パタトクカシーー\"\n",
    "out_01 = \"\".join([in_01[i] for i in range(0, 8, 2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'パトカー'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [02. 「パトカー」＋「タクシー」＝「パタトクカシーー」](https://nlp100.github.io/ja/ch01.html#02-%E3%83%91%E3%83%88%E3%82%AB%E3%83%BC%E3%82%BF%E3%82%AF%E3%82%B7%E3%83%BC%E3%83%91%E3%82%BF%E3%83%88%E3%82%AF%E3%82%AB%E3%82%B7%E3%83%BC%E3%83%BC)\n",
    "「パトカー」＋「タクシー」の文字を先頭から交互に連結して文字列「パタトクカシーー」を得よ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_02 = [\"パトカー\", \"タクシー\"]\n",
    "out_02 = \"\".join([p+t for p, t in zip(\"パトカー\", \"タクシー\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'パタトクカシーー'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [03. 円周率](https://nlp100.github.io/ja/ch01.html#03-%E5%86%86%E5%91%A8%E7%8E%87)\n",
    "\"Now I need a drink, alcoholic of course, after the heavy lectures involving quantum mechanics.\"という文を単語に分解し，各単語の（アルファベットの）文字数を先頭から出現順に並べたリストを作成せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_03 = \"Now I need a drink, alcoholic of course, after the heavy lectures involving quantum mechanics.\"\n",
    "out_03 = []\n",
    "buffer = \"\"\n",
    "\n",
    "for char in sentence_03:\n",
    "    if char == \" \" or char == \",\" or char == \".\":\n",
    "        if buffer != \"\":\n",
    "            out_03.append(len(buffer))\n",
    "            buffer = \"\"\n",
    "    else:\n",
    "        buffer += char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 1, 4, 1, 5, 9, 2, 6, 5, 3, 5, 8, 9, 7, 9]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_03"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [04. 元素記号](https://nlp100.github.io/ja/ch01.html#04-%E5%85%83%E7%B4%A0%E8%A8%98%E5%8F%B7)\n",
    "\"Hi He Lied Because Boron Could Not Oxidize Fluorine. New Nations Might Also Sign Peace Security Clause. Arthur King Can.\"という文を単語に分解し，1, 5, 6, 7, 8, 9, 15, 16, 19番目の単語は先頭の1文字，それ以外の単語は先頭に2文字を取り出し，取り出した文字列から単語の位置（先頭から何番目の単語か）への連想配列（辞書型もしくはマップ型）を作成せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_04 = \"Hi He Lied Because Boron Could Not Oxidize Fluorine. New Nations Might Also Sign Peace Security Clause. Arthur King Can.\"\n",
    "words = []\n",
    "buffer = \"\"\n",
    "\n",
    "for char in sentence_04:\n",
    "    if char == \" \" or char == \",\" or char == \".\":\n",
    "        if buffer != \"\":\n",
    "            words.append(buffer)\n",
    "            buffer = \"\"\n",
    "    else:\n",
    "        buffer += char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_04 = {}\n",
    "one_word_indices = [0, 4, 5, 6, 7, 8, 14, 15, 18]\n",
    "\n",
    "for i, word in enumerate(words):\n",
    "    if i in one_word_indices:\n",
    "        out_04[i+1] = word[0]\n",
    "    else:\n",
    "        out_04[i+1] = word[0] + word[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'H',\n",
       " 2: 'He',\n",
       " 3: 'Li',\n",
       " 4: 'Be',\n",
       " 5: 'B',\n",
       " 6: 'C',\n",
       " 7: 'N',\n",
       " 8: 'O',\n",
       " 9: 'F',\n",
       " 10: 'Ne',\n",
       " 11: 'Na',\n",
       " 12: 'Mi',\n",
       " 13: 'Al',\n",
       " 14: 'Si',\n",
       " 15: 'P',\n",
       " 16: 'S',\n",
       " 17: 'Cl',\n",
       " 18: 'Ar',\n",
       " 19: 'K',\n",
       " 20: 'Ca'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_04"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [05. n-gram](https://nlp100.github.io/ja/ch01.html#05-n-gram)\n",
    "与えられたシーケンス（文字列やリストなど）からn-gramを作る関数を作成せよ．この関数を用い，\"I am an NLPer\"という文から単語bi-gram，文字bi-gramを得よ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_n_gram(sequence, n: int):\n",
    "    n_gram = []\n",
    "\n",
    "    for i in range(len(sequence)-n+1):\n",
    "        element = \"\".join([sequence[j] for j in range(i, i+n)])\n",
    "        n_gram.append(element)\n",
    "\n",
    "    return n_gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "単語bi-gram : ['Iam', 'aman', 'anNLPer']\n",
      "文字bi-gram : ['I ', ' a', 'am', 'm ', ' a', 'an', 'n ', ' N', 'NL', 'LP', 'Pe', 'er']\n"
     ]
    }
   ],
   "source": [
    "print(\"単語bi-gram : %s\" % create_n_gram(\"I am an NLPer\".split(), 2))\n",
    "print(\"文字bi-gram : %s\" % create_n_gram(\"I am an NLPer\", 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [06. 集合](https://nlp100.github.io/ja/ch01.html#06-%E9%9B%86%E5%90%88)\n",
    "\"paraparaparadise\"と\"paragraph\"に含まれる文字bi-gramの集合を，それぞれ, XとYとして求め，XとYの和集合，積集合，差集合を求めよ．さらに，'se'というbi-gramがXおよびYに含まれるかどうかを調べよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = set(create_n_gram(\"paraparaparadise\", 2))\n",
    "Y = set(create_n_gram(\"paragraph\", 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "和集合 : {'ph', 'ag', 'ra', 'ap', 'ar', 'ad', 'se', 'di', 'pa', 'is', 'gr'}\n",
      "積集合 : {'ap', 'ra', 'pa', 'ar'}\n",
      "差集合(X\\Y) : {'di', 'is', 'ad', 'se'}\n",
      "差集合(Y\\X) : {'ag', 'ph', 'gr'}\n"
     ]
    }
   ],
   "source": [
    "print(\"和集合 : %s\" % (X|Y))\n",
    "print(\"積集合 : %s\" % (X&Y))\n",
    "print(\"差集合(X\\Y) : %s\" % (X-Y))\n",
    "print(\"差集合(Y\\X) : %s\" % (Y-X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"se\" is included in X : True\n",
      "\"se\" is included in Y : False\n"
     ]
    }
   ],
   "source": [
    "print(\"\\\"se\\\" is included in X : %s\" % (\"se\" in X))\n",
    "print(\"\\\"se\\\" is included in Y : %s\" % (\"se\" in Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [07. テンプレートによる文生成](https://nlp100.github.io/ja/ch01.html#07-%E3%83%86%E3%83%B3%E3%83%97%E3%83%AC%E3%83%BC%E3%83%88%E3%81%AB%E3%82%88%E3%82%8B%E6%96%87%E7%94%9F%E6%88%90)\n",
    "引数x, y, zを受け取り「x時のyはz」という文字列を返す関数を実装せよ．さらに，x=12, y=\"気温\", z=22.4として，実行結果を確認せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_template(x, y, z):\n",
    "    return \"%s時の%sは%s\" % (x, y, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'12時の気温は22.4'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_template(12, \"気温\", 22.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [08. 暗号文](https://nlp100.github.io/ja/ch01.html#08-%E6%9A%97%E5%8F%B7%E6%96%87)\n",
    "与えられた文字列の各文字を，以下の仕様で変換する関数cipherを実装せよ．\n",
    "* 英小文字ならば(219 - 文字コード)の文字に置換\n",
    "* その他の文字はそのまま出力\n",
    "\n",
    "この関数を用い，英語のメッセージを暗号化・復号化せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cipher(sentence: str):\n",
    "    encode = \"\"\n",
    "\n",
    "    for char in sentence:\n",
    "        if ord(\"a\") <= ord(char) <= ord(\"z\"):\n",
    "            encode += chr(219-ord(char))\n",
    "        else:\n",
    "            encode += char\n",
    "\n",
    "    return encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_08 = \"I couldn't believe that I could actually understand what I was reading : the phenomenal power of the human mind .\"\n",
    "encode = cipher(sentence_08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I xlfowm'g yvorvev gszg I xlfow zxgfzoob fmwvihgzmw dszg I dzh ivzwrmt : gsv ksvmlnvmzo kldvi lu gsv sfnzm nrmw .\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rehpic(sentence: str):\n",
    "    decode = \"\"\n",
    "\n",
    "    for char in sentence:\n",
    "        if ord(\"a\") <= 219-ord(char) <= ord(\"z\"):\n",
    "            decode += chr(219-ord(char))\n",
    "        else:\n",
    "            decode += char\n",
    "\n",
    "    return decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I couldn't believe that I could actually understand what I was reading : the phenomenal power of the human mind .\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cipher(encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [09. Typoglycemia](https://nlp100.github.io/ja/ch01.html#09-typoglycemia)\n",
    "スペースで区切られた単語列に対して，各単語の先頭と末尾の文字は残し，それ以外の文字の順序をランダムに並び替えるプログラムを作成せよ．ただし，長さが４以下の単語は並び替えないこととする．適当な英語の文（例えば\"I couldn't believe that I could actually understand what I was reading : the phenomenal power of the human mind .\"）を与え，その実行結果を確認せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def typoglycemia(sentence: str):\n",
    "    if len(sentence) > 4:\n",
    "        between = \"\".join([char for char in sample(sentence[1:-1], len(sentence)-2)])\n",
    "        return sentence[0] + between + sentence[-1]\n",
    "    else:\n",
    "        return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Imlootn a aae dngwteuv threl  ponuh l san awdpfcIiysh hahdelrdmntue la eu deaeu 'ccoIm nwa  n:tiit ehb odltter n.\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_09 = \"I couldn't believe that I could actually understand what I was reading : the phenomenal power of the human mind .\"\n",
    "typoglycemia(sentence_09)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Toclypeymgia'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_09 = \"Typoglycemia\"\n",
    "typoglycemia(sentence_09)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'foo'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_09 = \"foo\"\n",
    "typoglycemia(sentence_09)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
